#import "@local/note_template:0.1.0": *
#show: doc => note_template([Computational Mathematics], doc)

In this particular case, the course aim to a build theoretical and practical
knowledge in fields like numerical analysis and optimization.

The course will cover numerical algorithms with particular attention on
performance and minimization of approximation error.

Generally speaking, the #strong[linear algebra] defines rules to manipulate
#strong[vectors] by adding them together and multiply them by a scalar.

A vector can be many things, the most known type of vector is denoted as
$arrow(v)$ and it is used typically in physics; it can be seen as
$n$-dimensional point such that there is an #emph[arrow] starting from the
origin and pointing in that exact point. Also polynomials are vectors, but in
machine learning they are seen as elements of $bb(R)^n$.

= Index <index>

- Linear Systems
- Matrices
- Linear Independence
- Vector Space Basis
- Matrix Rank
- Vector Norms
- Orthogonality
- Eigenvalues Eigenvectors
- Singular Value Decomposition
- Pseudoinverse
- Least Aquares
- Low Rank Approximation

= References <references>

- Linear Algebra

- #link(
    "https://elearning.di.unipi.it/course/view.php?id=1048",
  )[Course Web Page]
